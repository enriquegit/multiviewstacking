{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17aed177",
   "metadata": {},
   "source": [
    "# Example of training a  MultiViewStacking classifier.\n",
    "\n",
    "This document shows how to use the `multiviestacking` library on a dataset with $2$ views. The library supports an arbitrary number of views (only limited by your computer's memory).\n",
    "\n",
    "### The HTAD dataset.\n",
    "\n",
    "The Home-Tasks Activities Dataset contains wrist-accelerometer and audio features collected by individuals performing at-home tasks such as sweeping, brushing teeth, washing hands, and watching TV. The dataset is included in the same directory as this document ('htad.csv'). We will use this database to build a Multi-View Stacking model with two views. One view for the audio features and one view for the accelerometer features. For more information about the dataset, check [this](https://osf.io/preprints/osf/j723c). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a6924",
   "metadata": {},
   "source": [
    "### Load the dataset.\n",
    "\n",
    "First, let's load the dataset into a pandas data frame and display the first rows.\n",
    "The first column is the **class** and the remaining ones are the features. The feature names have a prefix of **v1_*** or **v2_***.* The features prefixed with v1_ are mel frequency cepstral coefficients extracted from audio signals. Features prefixed with v2_ are summary statistics extracted from accelerometer signals. Note that column names can be anything. But to make things easier, in this case a prefix was added so we can get the corresponding views' column indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read file.\n",
    "df = pd.read_csv('htad.csv')\n",
    "\n",
    "# Display the first rows of the data.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd9917",
   "metadata": {},
   "source": [
    "### Encode the labels as integers\n",
    "\n",
    "`multiviewstacking` expects the labels to be in integer format. You can use a `LabelEncoder()` to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create the LabelEncoder object.\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply the transformation to the \"class\" column.\n",
    "df[\"class\"] = le.fit_transform(df[\"class\"])\n",
    "\n",
    "# Check the unique new values.\n",
    "np.unique(df[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdda800",
   "metadata": {},
   "source": [
    "Now let's store the class in the variable `y` and the features in the variable `X`. We also store the column names so later we can get the column indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"class\"]\n",
    "\n",
    "X = df.drop([\"class\"], axis = 1)\n",
    "\n",
    "# Store column names.\n",
    "colnames = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8f210",
   "metadata": {},
   "source": [
    "### Split the dataset\n",
    "\n",
    "Now we split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7540a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train, and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size = 0.5,\n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6e98b",
   "metadata": {},
   "source": [
    "### Get column indices\n",
    "\n",
    "The `MultiViewStacking` object expects the features of each view to be passed as indices. Either as ranges as a tuple or the complete list of indices. In this case we will pass the complete list of indices. Since we stored the column names, we can extract their indices by searching for those that start with \"v1_\" and \"v2_\". This can also be done manually or using a different method. The important thing is to have one list (per view) with the corresponding column indices with respect to the input training data `X`. In the example below, the indices for the first view (audio features) go from $0$ to $35$. This could also have been represented with a tuple like `(0,35)`. The `multiviewstacking` library allows the list format in case the features are not contiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column indices for each view.\n",
    "ind_v1 = [colnames.index(x) for x in colnames if \"v1_\" in x]\n",
    "ind_v2 = [colnames.index(x) for x in colnames if \"v2_\" in x]\n",
    "\n",
    "print(ind_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abe799",
   "metadata": {},
   "source": [
    "### Defining te first-level-learners and meta-learner\n",
    "\n",
    "Let's define the first level learners for each of the views and the meta-learner. The `multiviewstacking` library supports most of `scikit-learn` classifiers. A `MultiViewStacking` model is not limited to a single type of model but supports heterogenous types of models. For example, if you know that a KNN classifier is more suitable for audio classification and Gaussian Naive Bayes is better for the accelerometer view, you can specify a different model for each view. Furthermore, you can even specify a different model for the meta-learner. In this case, a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a26fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the first-level-learner for the audio view.\n",
    "# In this case, a KNN classifier with k=3. \n",
    "m_v1 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Define the first-level-learner for the accelerometer view.\n",
    "# In this case, a Naive Bayes classifier.\n",
    "m_v2 = GaussianNB()\n",
    "\n",
    "# Define the meta-learner.\n",
    "m_meta = RandomForestClassifier(n_estimators=50, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a38ac6",
   "metadata": {},
   "source": [
    "### Create the MultiViewStacking classifier\n",
    "\n",
    "Now we are ready to create our `MultiViewStacking` classifier. We first pass the `views_indices` parameter as a list of lists. The first list is the list of indices of the first view (audio), the second list is the list of indices of the second view (accelerometer). Then, we pass a list of `first_level_learners`. **Note that the order of the views for all parameters must be the same.** That is, if in `view_indices` you pass the indices of some view $A$ and view $B$ then in the `first_level_learners` you must pass a list with the corresponding models for view $A$ and view $B$ in the same order.\n",
    "\n",
    "Then, we specify the `meta_learner` and `k`. The parameter `k` specifies the number of folds in the internal cross-validation of the Multi-View Stacking algorithm. See [here](https://enriquegit.github.io/behavior-free/ensemble.html#stacked-generalization) for details of the algorithm.\n",
    "\n",
    "Finally we set the `random_state` parameter for reproducibility. The `random_state` value is passed to the internal cross-validation procedure that splits the data into folds. This parameter is optional with a default value of `123`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiviewstacking import MultiViewStacking\n",
    "\n",
    "model = MultiViewStacking(views_indices = [ind_v1, ind_v2],\n",
    "                      first_level_learners = [m_v1, m_v2],\n",
    "                      meta_learner = m_meta,\n",
    "                      k = 10,\n",
    "                      random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb642c3",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Once the model has been created, we can proceed to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44270a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's time to fit the model with the training data.\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374e109",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Now you can test your model by making predictions on the test set and computing the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print accuracy.\n",
    "print(np.sum(y_test == predictions) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f3504",
   "metadata": {},
   "source": [
    "### Convert predictions to original strings\n",
    "\n",
    "You can use the `LabelEncoder` to convert the integer predictions back to strings with its method `inverse_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 10 predictions with the original names.\n",
    "string_predictions = le.inverse_transform(predictions)\n",
    "print(string_predictions[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe94694",
   "metadata": {},
   "source": [
    "You can try changing the first-level-learners and meta-learner and see if you get better results. Be aware that if you try different classifiers and/or parameters you should do so with an independent validation set. Once you have found the best combination of models and parameters, you test the final model on an independent test set only once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a647cc4",
   "metadata": {},
   "source": [
    "### Testing the first-level-learners individually\n",
    "\n",
    "The fitted `MultiViewStacking` model has several attributes including `fitted_first_level_learners_`. You can use this to test the performance of the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fitted KNN.\n",
    "fitted_view1 = model.fitted_first_level_learners_[0]\n",
    "\n",
    "# Get the fitted Naive Bayes.\n",
    "fitted_view2 = model.fitted_first_level_learners_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using only the view 1 (audio) model.\n",
    "predictions_v1 = fitted_view1.predict(X_test.values[:,ind_v1])\n",
    "\n",
    "# Print accuracy.\n",
    "print(np.sum(y_test == predictions_v1) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a694d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using only the view 2 (accelerometer) model.\n",
    "predictions_v2 = fitted_view2.predict(X_test.values[:,ind_v2])\n",
    "\n",
    "# Print accuracy.\n",
    "print(np.sum(y_test == predictions_v2) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6309f",
   "metadata": {},
   "source": [
    "Note that for each views' fitted model we only pass the corresponding column features `inv_v1` and `inv_v2`. In his case, the individual models performed much worse compared to combining the views with Multi-View Stacking.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
